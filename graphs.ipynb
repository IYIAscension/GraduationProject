{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2c002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "# this is so we can render big dendogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d6ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_verbose(project):\n",
    "    pitestOutput = subprocess.run([\"mvn\", \"test-compile\", \"-Dverbose=true\", \"-Drat.skip=true\", \"-Dfeatures=+characteristics\", \"org.pitest:pitest-maven:mutationCoverage\"], capture_output=True, cwd=\"projects/\" + project, text=True)\n",
    "    with open(\"verboseOutputs/\" + project + \"-pitestOutput.txt\", \"w\") as f:\n",
    "        f.write(pitestOutput.stdout)\n",
    "    return pitestOutput.stdout.split(\"\\n\")\n",
    "\n",
    "def read_verbose(project):\n",
    "    with open(\"verboseOutputs/\" + project + \"-pitestOutput.txt\") as f:\n",
    "        pitestOutput = f.readlines()\n",
    "        pitestOutput.append(\"filler\")\n",
    "        return pitestOutput\n",
    "\n",
    "def export_clusters(labels, csv_data, export_dir):\n",
    "    df = pandas.DataFrame(columns=[\"id\", \"cluster_id\"])\n",
    "    for i in range(0, len(labels)):\n",
    "        df = df.append({\"id\": csv_data[\"id\"][i], \"cluster_id\": labels[i]}, ignore_index=True)\n",
    "\n",
    "    df.to_csv(export_dir + \"/clustering/clusters.csv\", sep=\",\", index=False)\n",
    "    return df\n",
    "\n",
    "def execute_mutantsV2(project, labels, data, seed):\n",
    "    includeTimings = []\n",
    "    excludeTimings = []\n",
    "    start_time = time.time()\n",
    "    pitestOutputFile = open(\"verboseOutputs/\" + project + \"-pitestOutput.txt\", \"r\")\n",
    "    excludeTimings.append(time.time() - start_time)\n",
    "    df = pandas.DataFrame(columns=[\"id\", \"cluster_id\"])\n",
    "    for i in range(0, len(labels)):\n",
    "        df = df.append({\"id\": data[\"id\"][i], \"cluster_id\": labels[i]}, ignore_index=True)\n",
    "    clusters = df[\"cluster_id\"].unique()\n",
    "    for cluster_id in clusters:\n",
    "        tmp = df[df[\"cluster_id\"] == cluster_id]\n",
    "        mutantID = tmp.sample(random_state=seed).iloc[0][\"id\"]\n",
    "        start_time = time.time()\n",
    "        mutantID = mutantID[:45] + mutantID[45:].replace(\" \", \", \")\n",
    "        found = 0\n",
    "        endOfFileReached = 1\n",
    "        for line in pitestOutputFile:\n",
    "            if found == 0 and mutantID in line:\n",
    "                found = 1\n",
    "            elif found == 1:\n",
    "                if \"MutationDetails [id=MutationIdentifier [location=Location\" in line:\n",
    "                    includeTimings.append(5)\n",
    "                    endOfFileReached = 0\n",
    "                    break\n",
    "                elif \"replaced\" in line:\n",
    "                    includeTimings.append(int(line.split(\" \")[-2]) * 0.001)\n",
    "                elif \"processed\" in line:\n",
    "                    includeTimings.append(int(line.split(\" \")[-2]) * 0.001)\n",
    "                    endOfFileReached = 0\n",
    "                    break\n",
    "        # If found is 0, the end of file was reached without finding the mutation,\n",
    "        # therefore there was no coverage. If true, it was the last mutation in the\n",
    "        # output and timed out.\n",
    "        if endOfFileReached and found:\n",
    "            includeTimings.append(5)\n",
    "        excludeTimings.append(time.time() - start_time)\n",
    "\n",
    "    return sum(includeTimings) - sum(excludeTimings)\n",
    "\n",
    "def execute_mutants(project, labels, data, seed):\n",
    "    includeTimings = []\n",
    "    excludeTimings = []\n",
    "    start_time = time.time()\n",
    "    pitestOutput = np.array(read_verbose(project))\n",
    "    excludeTimings.append(time.time() - start_time)\n",
    "    df = pandas.DataFrame(columns=[\"id\", \"cluster_id\"])\n",
    "    for i in range(0, len(labels)):\n",
    "        df = df.append({\"id\": data[\"id\"][i], \"cluster_id\": labels[i]}, ignore_index=True)\n",
    "    clusters = df[\"cluster_id\"].unique()\n",
    "    for cluster_id in clusters:\n",
    "        tmp = df[df[\"cluster_id\"] == cluster_id]\n",
    "        mutantID = tmp.sample(random_state=seed).iloc[0][\"id\"]\n",
    "        start_time = time.time()\n",
    "        mutantID = mutantID[:45] + mutantID[45:].replace(\" \", \", \")\n",
    "        mutantIdx = [i for i, line in enumerate(pitestOutput) if mutantID in line]\n",
    "        if len(mutantIdx) > 0:\n",
    "            startIndex = mutantIdx[0]\n",
    "        else:\n",
    "            excludeTimings.append(time.time() - start_time)\n",
    "            continue\n",
    "        found = 0\n",
    "        for line in pitestOutput[startIndex+1:]:\n",
    "            if \"MutationDetails [id=MutationIdentifier [location=Location\" in line:\n",
    "                includeTimings.append(5)\n",
    "                found = 1\n",
    "                break\n",
    "            elif \"replaced\" in line:\n",
    "                includeTimings.append(int(line.split(\" \")[-2]) * 0.001)\n",
    "            elif \"processed\" in line:\n",
    "                includeTimings.append(int(line.split(\" \")[-2]) * 0.001)\n",
    "                found = 1\n",
    "                break\n",
    "        if found == 0:\n",
    "            includeTimings.append(5)\n",
    "        excludeTimings.append(time.time() - start_time)\n",
    "\n",
    "    return sum(includeTimings) - sum(excludeTimings)\n",
    "\n",
    "def clusteredTestingSimulation(project, cur_seed, reduction, timingFile):\n",
    "    start_time = time.time()\n",
    "    csv_path = \"projects/\" + project\n",
    "    try:\n",
    "        data = pandas.read_csv(csv_path + \"/target/pit-reports/clustering/characteristics.csv\",\n",
    "                                names=[\"id\", \"mutOperator\", \"opcode\", \"returnType\",\n",
    "                                        \"localVarsCount\", \"isInTryCatch\", \"isInFinalBlock\",\n",
    "                                        \"className\", \"methodName\", \"blockNumber\", \"lineNumber\",\n",
    "                                        \"numTests\"],\n",
    "                                skiprows=1)\n",
    "    except FileNotFoundError:\n",
    "        data = pandas.read_csv(csv_path + \"/processor/target/pit-reports/clustering/characteristics.csv\",\n",
    "                                names=[\"id\", \"mutOperator\", \"opcode\", \"returnType\",\n",
    "                                        \"localVarsCount\", \"isInTryCatch\", \"isInFinalBlock\",\n",
    "                                        \"className\", \"methodName\", \"blockNumber\", \"lineNumber\",\n",
    "                                        \"numTests\"],\n",
    "                                skiprows=1)\n",
    "\n",
    "\n",
    "    # define ordinal encoding\n",
    "    encoder = LabelEncoder()\n",
    "    data = data[[\"id\", \"mutOperator\", \"opcode\", \"returnType\",\n",
    "                    \"localVarsCount\", \"isInTryCatch\", \"isInFinalBlock\", \"className\", \"methodName\",\n",
    "                    \"blockNumber\", \"lineNumber\", \"numTests\"]]\n",
    "    # Transform each column.. do id last since we need to inverse that.\n",
    "    for col in [\"mutOperator\", \"returnType\", \"className\", \"methodName\", \"id\"]:\n",
    "        data[col] = encoder.fit_transform(data[col])\n",
    "\n",
    "    clustering = AgglomerativeClustering(distance_threshold=None,\n",
    "                                            n_clusters=int(math.ceil(len(data) * reduction)),\n",
    "                                            linkage=\"ward\",\n",
    "                                            compute_distances=True)\n",
    "    clusters = clustering.fit(data)\n",
    "\n",
    "    # unlabel id so we can recognize the mutants\n",
    "    data[\"id\"] = encoder.inverse_transform(data[\"id\"])\n",
    "    resultTime = execute_mutants(project, clusters.labels_, data, cur_seed)\n",
    "    simulationTime = time.time() - start_time\n",
    "    timingFile.write(str(reduction) + \", \" + str(simulationTime) + \", \" + str(resultTime) + \", \" + str(simulationTime + resultTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544c776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipped = [\"zxing\", \"commons-lang\", \"jodatime\", \"jfreechart\", ]\n",
    "# projects = [\"google-auto-service\", \"google-auto-common\", \"scribejava-core\", \"google-auto-factory\", \"commons-csv\",\n",
    "#                 \"commons-cli\", \"google-auto-value\", \"gson\", \"commons-io\",\"commons-text\", \"commonc-codec\", ]\n",
    "# projects1 = [\"commons-text\", \"commonc-codec\", ]\n",
    "seeds = [\n",
    "    66304, 16389, 14706, 91254, 49890, 86054, 55284, 77324, 36147, 13506, 73920, 80157, 43981, 75358, 33399, 56134,\n",
    "    13388, 81617, 90957, 52113, 20428, 26482, 56340, 31018, 32067, 13067, 8339, 49008, 125894, 68282, ]\n",
    "#timesProjects1 = [212, 3467, 1276, 8993, 11280, 34, 624, 443]\n",
    "projects1 = [\"commons-cli\", \"commons-text\", \"commons-codec\", \"commons-io\", \"google-auto-value\", \"google-auto-service\", \"google-auto-factory\", \"google-auto-common\", ]\n",
    "projects = [\"google-auto-service\", \"google-auto-factory\", \"google-auto-common\" ]\n",
    "reductions = [0.1, 0.25, 0.5, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23077e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-auto-service\n",
      "google-auto-factory\n",
      "google-auto-common\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtimings/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m project \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-timings\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m reduction \u001b[39min\u001b[39;00m reductions:\n\u001b[0;32m----> 7\u001b[0m     clusteredTestingSimulation(project, seeds[\u001b[39m0\u001b[39;49m], reduction, file)\n\u001b[1;32m      8\u001b[0m file\u001b[39m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn [2], line 92\u001b[0m, in \u001b[0;36mclusteredTestingSimulation\u001b[0;34m(project, cur_seed, reduction, timingFile)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m# unlabel id so we can recognize the mutants\u001b[39;00m\n\u001b[1;32m     91\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minverse_transform(data[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 92\u001b[0m resultTime \u001b[39m=\u001b[39m execute_mutants(project, clusters\u001b[39m.\u001b[39;49mlabels_, data, cur_seed)\n\u001b[1;32m     93\u001b[0m simulationTime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m     94\u001b[0m timingFile\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(reduction) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(simulationTime) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(resultTime) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(simulationTime \u001b[39m+\u001b[39m resultTime))\n",
      "Cell \u001b[0;32mIn [2], line 37\u001b[0m, in \u001b[0;36mexecute_mutants\u001b[0;34m(project, labels, data, seed)\u001b[0m\n\u001b[1;32m     35\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     36\u001b[0m mutantID \u001b[39m=\u001b[39m mutantID[:\u001b[39m45\u001b[39m] \u001b[39m+\u001b[39m mutantID[\u001b[39m45\u001b[39m:]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m mutantIdx \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pitestOutput) \u001b[39mif\u001b[39;00m mutantID \u001b[39min\u001b[39;00m line]\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mutantIdx) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     39\u001b[0m     startIndex \u001b[39m=\u001b[39m mutantIdx[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn [2], line 37\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     36\u001b[0m mutantID \u001b[39m=\u001b[39m mutantID[:\u001b[39m45\u001b[39m] \u001b[39m+\u001b[39m mutantID[\u001b[39m45\u001b[39m:]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m mutantIdx \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pitestOutput) \u001b[39mif\u001b[39;00m mutantID \u001b[39min\u001b[39;49;00m line]\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mutantIdx) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     39\u001b[0m     startIndex \u001b[39m=\u001b[39m mutantIdx[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_time = 0\n",
    "\n",
    "for project in projects:\n",
    "    print(project)\n",
    "    file = open(\"timings/\" + project + \"-timings\", \"w\")\n",
    "    for reduction in reductions:\n",
    "        clusteredTestingSimulation(project, seeds[0], reduction, file)\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "# directory = \"expirements_results\"\n",
    "# seeds = [\n",
    "#     66304, 16389, 14706, 91254, 49890, 86054, 55284, 77324, 36147, 13506, 73920, 80157, 43981, 75358, 33399, 56134,\n",
    "#     13388, 81617, 90957, 52113, 20428, 26482, 56340, 31018, 32067, 13067, 8339, 49008, 125894, 68282, ]\n",
    "# for project in projects:\n",
    "#     results_df = pandas.DataFrame(columns=[\"seed\", \"reduction\", \"score\", \"acc_avg\", \"acc_min\", \"acc_max\", ])\n",
    "#     for seed in seeds:\n",
    "#         print(str(seed))\n",
    "#         results_df = do_exp1_full(directory, project, seed, results_df, True)\n",
    "\n",
    "#     results_df.to_csv(directory + \"/full\" + \"/results_exp_\" + project + \".csv\", sep=\",\",\n",
    "#                         index=False, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
