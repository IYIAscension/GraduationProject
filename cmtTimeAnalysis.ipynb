{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de762757",
   "metadata": {},
   "source": [
    "This file was made to calculate the time Clustered Mutation Testing takes for projects with the correct pom.xml configuration.\n",
    "\n",
    "More in-depth discussion is in Adam Abdalla's thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from os import path\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executes pitest for given project, includes test compilation.\n",
    "def compile_tests(project: str) -> str:\n",
    "    pitestOutput = subprocess.run([\"mvn\", \"test-compile\"], capture_output=True, cwd=\"projectsTA/\" + project, text=True)\n",
    "    return pitestOutput\n",
    "\n",
    "# Executes pitest for given project.\n",
    "def execute_normal(project: str) -> str:\n",
    "    pitestOutput = subprocess.run([\"mvn\", \"-Drat.skip=true\", \"org.pitest:pitest-maven:mutationCoverage\"], capture_output=True, cwd=\"projectsTA/\" + project, text=True)\n",
    "    return pitestOutput\n",
    "\n",
    "# Executes pitest for given project, writes verbose output to file and returns a list of it.\n",
    "def execute_verbose(project: str, addition: str=\"\") -> list:\n",
    "    pitestOutput = subprocess.run([\"mvn\", \"-Dverbose=true\", \"-Drat.skip=true\", \"-Dfeatures=+cluster\", \"org.pitest:pitest-maven:mutationCoverage\"], capture_output=True, cwd=\"projectsTA/\" + project, text=True)\n",
    "    with open(\"verboseOutputs/\" + project + addition  + \"-pitestOutput.txt\", \"w\") as verboseFile:\n",
    "        verboseFile.write(pitestOutput.stdout)\n",
    "    return pitestOutput.stdout.split(\"\\n\")\n",
    "\n",
    "# Executes pitest for given project, includes Pitest-Clustering-Plugin's characteristic extraction.\n",
    "def characteristics_extraction(project: str) -> str:\n",
    "    pitestOutput = subprocess.run([\"mvn\", \"-Drat.skip=true\", \"-Dfeatures=+characteristics\" \"org.pitest:pitest-maven:mutationCoverage\"], capture_output=True, cwd=\"projectsTA/\" + project, text=True)\n",
    "    return pitestOutput\n",
    "\n",
    "# Executes pitest for given project, but uses Pitest-Clustering-Plugin's clustering feature.\n",
    "def execute_cluster(project: str) -> str:\n",
    "    pitestOutput = subprocess.run([\"mvn\", \"-Drat.skip=true\", \"-Dfeatures=+cluster\", \"org.pitest:pitest-maven:mutationCoverage\"], capture_output=True, cwd=\"projectsTA/\" + project, text=True)\n",
    "    return pitestOutput\n",
    "\n",
    "\n",
    "# Reads the verbose output created by execute_verbose().\n",
    "def read_verbose(project: str) -> list:\n",
    "    with open(\"verboseOutputs/\" + project + \"-pitestOutput.txt\") as verboseFile:\n",
    "        pitestOutput = verboseFile.readlines()\n",
    "        pitestOutput.append(\"filler\")\n",
    "        return pitestOutput\n",
    "\n",
    "\n",
    "# Creates an mutant_id-cluster_id csv, so that the pitest-clustering-plugin\n",
    "# can be used to execute only one mutant per cluster.\n",
    "def export_clusters(labels: np.ndarray, csv_data: pd.DataFrame, export_dir: str) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(columns=[\"id\", \"cluster_id\"])\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        df = df.append({\"id\": csv_data[\"id\"][i], \"cluster_id\": labels[i]}, ignore_index=True)\n",
    "\n",
    "    df.to_csv(export_dir + \"/clustering/clusters.csv\", sep=\",\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Gets characteristics data from project file created by pitest clustering plugin.\n",
    "def getProjectDf(project: str) -> pd.DataFrame:\n",
    "    csv_path = \"projectsTA/\" + project\n",
    "    if path.exists(csv_path + \"/target/pit-reports/clustering/characteristics.csv\"):\n",
    "        data = pd.read_csv(csv_path + \"/target/pit-reports/clustering/characteristics.csv\",\n",
    "                                names=[\"id\", \"mutOperator\", \"opcode\", \"returnType\",\n",
    "                                        \"localVarsCount\", \"isInTryCatch\", \"isInFinalBlock\",\n",
    "                                        \"className\", \"methodName\", \"blockNumber\", \"lineNumber\",\n",
    "                                        \"numTests\"],\n",
    "                                skiprows=1)\n",
    "    else:\n",
    "        data = pd.read_csv(csv_path + \"/processor/target/pit-reports/clustering/characteristics.csv\",\n",
    "                                names=[\"id\", \"mutOperator\", \"opcode\", \"returnType\",\n",
    "                                        \"localVarsCount\", \"isInTryCatch\", \"isInFinalBlock\",\n",
    "                                        \"className\", \"methodName\", \"blockNumber\", \"lineNumber\",\n",
    "                                        \"numTests\"],\n",
    "                                skiprows=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# For each seed, simulates execution of CMT by creating the cluster.csv file where only 1 random\n",
    "# mutant per cluster is written to it and then using the \"execute_cluster()\" function.\n",
    "def execute_mutants(project: str, labels: np.ndarray, data: pd.DataFrame, seeds: list) -> list:\n",
    "    timings = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        start_time = time.time()\n",
    "        df = pd.DataFrame(columns=[\"id\", \"cluster_id\"])\n",
    "\n",
    "        for i in range(0, len(labels)):\n",
    "            df = df.append({\"id\": data[\"id\"][i], \"cluster_id\": labels[i]}, ignore_index=True)\n",
    "\n",
    "        clusters = df[\"cluster_id\"].unique()\n",
    "        mutants = []\n",
    "\n",
    "        for cluster_id in clusters:\n",
    "            tmp = df[df[\"cluster_id\"] == cluster_id]\n",
    "            mutantID = tmp.sample(random_state=seed).iloc[0][\"id\"]\n",
    "            mutants.append(mutantID)\n",
    "\n",
    "        filler = range(len(mutants))\n",
    "        df = pd.DataFrame({\"id\": mutants, \"filler\": filler})\n",
    "        csv_path = \"projectsTA/\" + project\n",
    "\n",
    "        if path.exists(csv_path + \"/target/\"):\n",
    "            df.to_csv(csv_path + \"/target/pit-reports/clustering/cluster.csv\", mode=\"w\")\n",
    "        else:\n",
    "            df.to_csv(csv_path + \"/processor/target/pit-reports/clustering/cluster.csv\", mode=\"w\")\n",
    "\n",
    "        execute_cluster(project)\n",
    "        timings.append(time.time() - start_time)\n",
    "        print(project + \": \" + str(timings))\n",
    "\n",
    "    return timings\n",
    "\n",
    "\n",
    "# Creates clusters and gives them to execute_mutants() to continue to\n",
    "def clusteredTestingSimulation(project: str, seeds: list, reduction: float, timingFile: str, useMeanshift: int=0):\n",
    "    start_time = time.time()\n",
    "    csv_path = \"projectsTA/\" + project\n",
    "    data = getProjectDf(project)\n",
    "\n",
    "    # define ordinal encoding\n",
    "    encoder = LabelEncoder()\n",
    "    data = data[[\"id\", \"mutOperator\", \"opcode\", \"returnType\",\n",
    "                    \"localVarsCount\", \"isInTryCatch\", \"isInFinalBlock\", \"className\", \"methodName\",\n",
    "                    \"blockNumber\", \"lineNumber\"]]\n",
    "\n",
    "    # Transform each column. Transform id last since we need to invert that.\n",
    "    for col in [\"mutOperator\", \"returnType\", \"className\", \"methodName\", \"id\"]:\n",
    "        data[col] = encoder.fit_transform(data[col])\n",
    "\n",
    "    if useMeanshift:\n",
    "        clustering = MeanShift(bandwidth=reduction, cluster_all=True)\n",
    "    else:\n",
    "        clustering = AgglomerativeClustering(distance_threshold=None,\n",
    "                        n_clusters=int(math.ceil(len(data) * reduction)),\n",
    "                        linkage=\"ward\",\n",
    "                        compute_distances=False)\n",
    "    clusters = clustering.fit(data)\n",
    "\n",
    "    # unlabel id so we can recognize the mutants\n",
    "    data[\"id\"] = encoder.inverse_transform(data[\"id\"])\n",
    "    simulationTime = time.time() - start_time\n",
    "    resultTime = execute_mutants(project, clusters.labels_, data, seeds)\n",
    "    timingFile.write(\",\" + str(simulationTime + np.mean(resultTime)) + \",\" + str(np.std(resultTime)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39abcdc6",
   "metadata": {},
   "source": [
    "Parameter cell down below. Note that these are not the only parameters you might want to change.\n",
    "\n",
    "Projects in the list should be in the projectsTA folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [\n",
    "    66304, 16389, 14706, 91254, 49890, 86054, 55284, 77324, 36147, 13506, 73920, 80157, 43981, 75358, 33399, 56134,\n",
    "    13388, 81617, 90957, 52113, 20428, 26482, 56340, 31018, 32067, 13067, 8339, 49008, 125894, 68282, ]\n",
    "projects = [ \"commons-csv\", \"commons-cli\",  \"commons-text\", \"commons-codec\", \"scribejava/scribejava-core\", \"google-auto-factory\", \"google-auto-common\"]\n",
    "reductions = [0.5, 0.25, 0.1]\n",
    "useMeanshift = 0\n",
    "bandwidths = [25, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23077e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFilename = \"timings/HierarchicalTimings.txt\"\n",
    "if useMeanshift:\n",
    "    outputFilename = \"timings/MSTimings.txt\"\n",
    "    reductions = bandwidths\n",
    "\n",
    "f = open(outputFilename, \"w\")\n",
    "f.write(\"project,full\")\n",
    "full_time = 0\n",
    "\n",
    "for reduction in reductions:\n",
    "    f.write(\",\" + str(reduction) + \" time avg,\" + str(reduction) + \" time std\")\n",
    "f.write(\"\\n\")\n",
    "\n",
    "# For every project, compile tests -> measure full time -> extract features -> measure CMT time\n",
    "# Ensure all measurements are written in the output file.\n",
    "for project in projects:\n",
    "    compile_tests(project)\n",
    "    print(\"Starting project: \" + project)\n",
    "    print(\"Executing the full mutation testing...\")\n",
    "    start_time = time.time()\n",
    "    execute_normal(project)\n",
    "    full_time = time.time() - start_time\n",
    "    print(\"Full mutation testing took: \" + str(full_time) + \" seconds.\")\n",
    "    f.write(project + \",\" + str(full_time))\n",
    "\n",
    "    if not path.exists(\"projectsTA/\" + project + \"/processor/target/pit-reports/clustering/characteristics.csv\") and not path.exists(\"projectsTA/\" + project + \"/target/pit-reports/clustering/characteristics.csv\"):\n",
    "        print(\"Extracting features for project: \" + project)\n",
    "        start_time = time.time()\n",
    "        characteristics_extraction(project)\n",
    "        print(\"Extracting features took: \" + str(time.time() - start_time) + \" seconds.\")\n",
    "\n",
    "    for reduction in reductions:\n",
    "        print(\"Starting reduction: \" + str(reduction))\n",
    "        clusteredTestingSimulation(project, seeds, reduction, f)\n",
    "        f.close()\n",
    "        f = open(outputFilename, \"a\")\n",
    "\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c295b91a4a4f8e66f37da6a2fbf5c84e6919990d10548059361442497be2c972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
